{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PythonDeepLearningBasePytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、 深度学习基础"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**`*.ipynb`转为需要的文档格式**\n",
    ">```bash\n",
    "># 进入到指定路径下\n",
    ">cd ./GGG/PytorchLearning/PythonDeepLearningBasePytorch/\n",
    ">```\n",
    ">- **转换为 markdown 文件**\n",
    "> \t ```bash\n",
    "> \t jupyter nbconvert --to markdown notebook.ipynb\n",
    "> \t ```\n",
    ">- **转换为 html 文件**\n",
    "> \t ```bash\n",
    "> \t jupyter nbconvert --to html notebook.ipynb\n",
    "> \t ```\n",
    ">- **转换为 pdf 文件**\n",
    "> \t ```bash\n",
    "> \t jupyter nbconvert --to pdf notebook.ipynb\n",
    "> \t ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 机器学习基础"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 机器学习的基本任务"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习的基本任务一般分为4大类：\n",
    "- 监督学习\n",
    "    - 定义: 使用已知正确答案的示例来训练模型\n",
    "    - 任务: 分类、回归、目标检测、识别 等\n",
    "    - 场景: 根据已有数据，分类或预测新数据\n",
    "- 无监督学习\n",
    "    - 定义: 在无标签的数据集中插值规则的模型\n",
    "    - 任务: 聚类、降维 等\n",
    "    - 场景: 从一堆人的身体测量值中算出XS、S、M、L 和 XL 号衬衫尺码\n",
    "- 半监督学习\n",
    "    - 定义: 结合分类与聚类的思想生成新模型\n",
    "    - 任务: 自编码、推荐、生成式对抗 等\n",
    "    - 场景: 根据已有数据，分类 或 预测 新数据\n",
    "- 强化学习\n",
    "    - 定义: 对没有标注数据集，但知是否更近目标来构建模型\n",
    "    - 任务: 分类、 回归 等\n",
    "    - 场景: 类似经典的儿童游戏 -- \"hotter or colder\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 监督学习\n",
    "监督学习是最常见的一种机器学习类型，其任务的特点是给定学习目标，这个学习目标又称标签、标注 或 实际值 等，\n",
    "整个学习过程就是围绕如何使预测与目标更接近而来的。\n",
    "近些年，随着深度学习的发展，分类除传统的二分类、多分类、多标签分类之外，也出现了一些新的内容: \n",
    "eg: 目标检测、目标识别、图像分割 等 监督学习的重要内容。 \n",
    "监督学习过程:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +-----------------------|    预处理    |    学习    |    验证    ｜      预测      ｜-------+\n",
    "    |                               +<-----------+         |标签|-->+                        |\n",
    "    |                               | 调整模型参数 |           |      |                       |\n",
    "    | |原始数据|标签|->Shuffle-->|训练数据|----->|计算损失|-->|最终模型|--+->|不带标签的新数据|      |\n",
    "    |                                                        |      |         |             |\n",
    "    |                          |测试数据|------------------>--+      |          +>|标签|      |\n",
    "    |                          |       |---------<------------------+                       |\n",
    "    +-----------------------|    预处理    |    学习    |    验证    ｜      预测      ｜-------+"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 无监督学习\n",
    "监督学习的输入数据中有标签或目标值，但在实际生活中，有很多数据没有标签 或者 标签代价很高。\n",
    "这些没有标签的数据也可能包含很重要的规则或信息，从这类数据中学习到一个规则或规律的过程被称为无监督学习。\n",
    "在无监督学习中，我们通过推断输入数据的结构来建模，模型包括关联学习、降维、聚类 等。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 半监督学习\n",
    "- 半监督学习是监督学习 与 无监督学习相结合的一种学习方法。 x\n",
    "- 半监督学习使用大量的未标记数据，同时由部分使用标记数据进行模式识别。 \n",
    "- 自编码器是一种半监督学习，其生成的目标就是未经修改的输入。 \n",
    "- 语言处理中根据给定文本中的词预测下一个词，也是半监督学习的例子。 \n",
    "- 对抗生成式网络也是一种半监督学习，给定一些真图片或语言，然后通过对抗生成网络生成一些与真图片或语言逼真的图形或语言。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 强化学习\n",
    "强化学习是机器学习的一个重要分支没事多学科领域交叉的一个产物。\n",
    "强化学习主要包含 4 个元素:\n",
    "- 智能体(Agent)\n",
    "- 环境状态\n",
    "- 行动\n",
    "- 奖励\n",
    "\n",
    "强化学习的目标就是获得最多的累计奖励。\n",
    "强化学习把学习看作一个试探评价的过程，Agent 选择一个动作用于环境，\n",
    "环境接受该动作后状态发生变化，同时产生一个强化信号(奖或惩)反馈给 Agent，\n",
    "Agent 根据强化信号和环境当前状态再选择下一个动作，选择的原则是使受到正强化(奖)的概率增大。\n",
    "选择的动作不仅影响立即强化值，也影响下一时刻的状态和最终的强化值。\n",
    "\n",
    "强化学习不同于监督学习，主要表现在教师信号上。\n",
    "强化学习中由环境提供的强化信号是 Agent 对所产生动作的好坏做的一种评价，而不是告诉 Agent 如何去产生正确的动作。\n",
    "由于外部环境只提供了很少的信息，所以 Agent 必须靠自身的经历进行学习。\n",
    "通过这种方式，Agent 在行动一一被评价的环境中获得知识，改进行动方案以适应环境。\n",
    "\n",
    "AlphaGo Zero 带有强化学习内容，它完全摒弃了人类知识，碾压了早期版本的 AlphaGo，更显现了强化学习和深度学习结合的强大威力。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 机器学习一般流程\n",
    "机器学习一般需要先定义问题、收集数据、探索数据、预处理数据，对数据处理后，接下来开始训练模型、评估模型，然后优化模型等步骤。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "+----------------+---------+---------------------------------+-----------------------+-----------|\n",
    "| 明确目标(收集数据)| 输入数据 |          数据探索与预处理          |   训练及测试算法或建模   |    评估    |\n",
    "|----------------+---------+---------------------------------+-----------------------+-----------|\n",
    "|                |         |                      数据清洗   -|->  训练数据 -> 模型训练<-+-<---+     |\n",
    "|                | 数据集合-|-> 数据探索与预处理 -->  数据转换    |               模型     |     |     |\n",
    "|                |         |                      补充规范数据-|->  测试数据 -> 测试模型--+->评估及优化 |\n",
    "|                |         |                                 |                       |   +-> 部署 |\n",
    "+----------------+---------+---------------------------------+-----------------------+-----------|\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 明确目标\n",
    "在实施一个机器学习项目之初，定义需求、明确目标、了解要解决的问题以及目标设计的范围等都非常重要，它们之间影响后续工作的质量甚至成败。\n",
    "1) 明确目标\n",
    "    首先需要明确大方向，比如当前的需求是分类问题还是预测问题或聚类问题等。\n",
    "2) 明确目标具体含义 \\\n",
    "清除大方向后，需要进一步明确目标的具体含义。\n",
    "    - 如果是分类问题，还需要区分是二分类、多分类还是多标签分类。\n",
    "    - 如果是预测问题，要去吧是标量预测还是向量预测。\n",
    "    - ...\n",
    "3) 确定问题\n",
    "    明确目标有助于选择模型架构、损失函数及评估方法等。\n",
    "当然，明确目标还包含需要了解目标的可行性，因为并不是所有问题都可以通过机器学习来解决。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 收集数据\n",
    "为解决上述的问题，需要哪些数据？数据是否充分？哪些数据能获取，哪些数据无法获取？这些数据是否包含我们学习的一些规则等。\n",
    "接下来是收集数据，数据可能涉及不同平台、不同系统、不同部分、不同形式等，对这些问题的了解有助于确定具体数据收集方案、实施步骤等。\n",
    "能收集的数据尽量实现自动化、程序化。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 数据探索与预处理\n",
    "收集到的数据，不一定规范和完整，这就需要对数据进行初步分析或探索，然后根据探索结果与问题目标，确定数据预处理方案。\n",
    "对数据探索包括 了解数据的大致结构、数据量、各特征的统计信息、整个数据质量情况、数据的分布情况等。\n",
    "为了更好的体现数据分布情况，数据可视化是一个不错的方法。\n",
    "\n",
    "通过对数据探索后，可能会发现不少问题：如存在缺失数据、数据不规范、数据分布不均衡、存在奇异数据、有很多非数值数据、存在很多无关或不重要的数据等。\n",
    "这些问题的存在直接影响数据质量，为此，数据预处理工作就应该是接下来的重点工作。\n",
    "数据预处理是机器学习过程中必不可少的重要步骤，特别是在生产环境中的机器学习，数据往往是原始、未加工和未处理过的，数据预处理常常占据整个机器学习过程的大部分时间。\n",
    "\n",
    "数据预处理过程，一般包括数据清理、数据转换、规范数据、特征选择等工作。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 选择模型及损失函数\n",
    "数据准备好后，接下来就是根据目标选择模型。\n",
    "模型选择可以先用一个简单、自身比较熟悉的方法来实现，用这个方法开发一个原型或比基准更好一点的模型。通过这个简单模型有助于快速了解整个项目的主要内容。\n",
    "- 了解整个项目的可行性、关键点。\n",
    "- 了解数据质量、数据是否充分等。\n",
    "- 为开发一个更好的模型奠定基础。\n",
    "\n",
    "在模型选择时，一般不存在某种对任何情况都表现很好的算法(这种现象又称为\"没有免费的午餐\")。\n",
    "因此在实际选择时，一般会选用几种不同的方法来训练模型，然后比较它们的性能，从中选择最优的那个。\n",
    "\n",
    "模型选择后，还需要考虑以下几个关键点：\n",
    "- 最后一层是否需要添加 softmax 或 sigmoid 激活层。\n",
    "- 选择合适损失函数。\n",
    "- 选择合适的优化器。\n",
    "\n",
    "下面提供了常见问题类型 最后一层激活函数 和 损失函数 的对应关系："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "+--------------+----------------+--------------------------------------------------------------------------+\n",
    "| 问题类型      |  最后一层激活函数 |    损失函数                                                               |\n",
    "+--------------+----------------+--------------------------------------------------------------------------+\n",
    "| 二分类，单标签 ｜      添加      | sigmoid 层 nn.BCELoss                                                     |\n",
    "|              |      不添加     | sigmoid 层 nn.BCEWithLogitsLoss                                          |\n",
    "| 二分类，多标签  |      无        | nn.SoftMarginLoss(target 为 1 或 -1)                                     |\n",
    "| 多分类，单标签  |      不添加    | softmax 层 nn.CrossEntroyLoss(target 的类型为 torch.LongTensor 的 one-hot) |\n",
    "|              |      添加      | softmax 层 nn.NLLLoss                                                     |\n",
    "| 多分类，多标签  |      无       | nn.MultiLabelsoftMarginLoss(target 为 0 或 1)                             |\n",
    "| 回归          |      无        | nn.MSELoss                                                               |\n",
    "| 识别          |      无        | nn.TripleMarginLoss                                                      |\n",
    "|              |                | nn.CosineEmbeddingLoss(margin 在 [-1, 1] 之间)                            |\n",
    "+--------------+----------------+--------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5 评估及优化模型\n",
    "模型确定后，还需要确定一种评估模型性能的方法，即评估方法。评估方法大致有 3 种：\n",
    "- 留出法\n",
    "    留出法的步骤相对简单，直接将数据集划分为两个互斥的集合，其中一个集合作为训练集，另一个作为测试集。 \\\n",
    "    在训练集上训练出模型后，用测试集来评估测试误差，作为泛化误差的估计。 \\\n",
    "    使用留出法，数据量较大时还可以优化出一种更好的方法，就是把数据分成 3 部分： \\\n",
    "    - 训练数据集: 用来训练模型。 \\\n",
    "    - 验证数据集: 用来调优超参数。 \\\n",
    "    - 测试数据集: 用来测试模型的泛化能力。 \\\n",
    "- K折交叉验证 \\\n",
    "    不重复地随机将训练数据集划分为 k 个，其中 k-1 个用于模型训练，剩余的一个用于测试。\n",
    "- 重复的K折交叉验证 \\\n",
    "    当数据量比较小，数据分布不很均匀时，可以采用这种方法。\n",
    "\n",
    "使用训练数据构建模型后，通常使用测试数据对模型进行测试，测试模型对新数据的适应情况。\n",
    "- 如果对模型的测试结果满意，就可以用此模型对以后的数据进行预测；\n",
    "- 如果对模型的测试结果不满意，可以优化模型。\n",
    "\n",
    "模型优化的方法很多，其中网格搜索参数是一种有效方法，当然也可以采用手工调节参数等方法。\n",
    "如果出现过拟合，尤其是回归类的问题，可以考虑正则化的方法来降低模型的泛化误差。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 过拟合与欠拟合"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 权重正则化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Dropout 正则化\n",
    "Dropout 在训练过程中，按一定的比例(比例参数可设置)随机忽略或屏蔽一些神经元。\n",
    "这些神经元会被随机\"抛弃\"，也就是说它们在正向传播中对于下游神经元的贡献效果暂时消失了，反向传播时该神经元也不会有任何权重的更新。\n",
    "故通过传播过程，Dropout将产生和L2范数相同的收缩权重的效果。\n",
    "\n",
    "随着神经网络模型的不断学习，神经元的权值会与整个网络的上下文相匹配。\n",
    "神经元的权重针对某些特征进行调优，进而产生一些特殊化。\n",
    "周围的神经元则会依赖于这种特殊化，但如果过于特殊化，模型会因为对训练数据的过拟合而变得脆弱不堪。\n",
    "神经元在训练过程中的这种依赖于上下文的现象被称为复杂的协同适应(Complex Co-Adaptations)。\n",
    "\n",
    "加入了 Dropout 后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。\n",
    "由于网络模型对神经元特定的权重不那么敏感。这反过来又提升了模型的泛化能力，不容易对训练数据过拟合。\n",
    "\n",
    "Dropout 训练的集成包括所有从基础网络除去非输出单元形成子网络。\n",
    "Dropout 训练所有子网络组成的集合，其中子网络是从基本网络中删除非输出单元所构建的。\n",
    "从具有两个可见单元和两个隐藏单元的基本网络开始，这 4 个单元有 16 个可能的子集。\n",
    "上述的例子中，所得的大部分网络没有输入单元或没有从输入连接到输出的路径。当层较宽时，丢弃所有从输入到输出的可能路径的概率变小，所以这个问题对于层较宽的网络不是很重要。\n",
    "\n",
    "Dropout在训练阶段和测试阶段是不同的，一般在训练时使用，测试阶段不使用。(不过测试时，为了平衡(因训练时舍弃了部分节点或输出)，一般将输出按Dropout Rate比例缩小)\n",
    "Dropout一般原则：\n",
    "- 通常丢弃率控制在20%-50%比较好，可以从20%开始尝试。(比例太低起不到效果，比例太高导致模型欠学习)\n",
    "- 在大的网络模型上应用\n",
    "  当Dropout应用在较大的网络模型时，更有可能得到效果的提升，模型有更多的机会学习到多种独立的表征\n",
    "- 在输入层和隐藏层都使用Dropout\n",
    "  对不同的层，设置的keep_prob也不同，一般来说神经元较少的层，会设keep_prob为1.0或接近于1.0的数；神经元较多的层，则会将keep_prob设置得较小，如0.5或更小\n",
    "- 增加学习速率和冲量\n",
    "  把学习速率扩大10-100倍，冲量值调高到0.9-0.99\n",
    "- 限制网络模型的权重\n",
    "  大的学习速率往往会导致大的权重值。对网络的权重值做最大范数的正则化，被证明能提升模型性能\n",
    "\n",
    "批量正则化：\n",
    "Batch Normalization 不仅可以有效的解决梯度消失问题，而且还可以让调试参数更加简单，在提高训练模型效率的同时，还可以让神经网络模型更加\"健壮\"。\n",
    "BN是对隐藏层对标准化处理，它与输入的标准化处理(Normalizing Inputs)是有区别的，Normalizing Inputs是使所有输入的均值为0，方差为1；BN可使各隐藏层输入的均值和方差为任意值。\n",
    "\n",
    "实际上，从激活函数的角度来看，如果各隐藏层的输入均值在靠近0的区域，即处于激活函数的线性区域，这样不利于训练好的非线性神经网络，而且得到的模型效果也不会太好。\n",
    "\n",
    "BN使用的范围尝试：一般在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时，可以尝试用BN来解决。\n",
    "                在一般情况下，也可以加入BN来加快训练速度，提高模型精度，还可以大大地提高训练模型的效率。\n",
    "BN功能：\n",
    "-  可以选择比较大的初始学习率，让训练速度飙升。之前还需要慢慢地调整学习率，甚至在网络训练到一半的时候，还需要想着学习率进一步调小的比例选择多少比较合适。 \\\n",
    "    可以采用初始很大的学习率，然而学习率的衰减速度也很快，因为这个算法收敛很快。即使选择较小的学习率，也比之前的收敛速度快，因为它具有快速训练收敛的特性。\n",
    "-  不用再去理会过拟合中Dropout、L2正则项参数的选择问题，采用BN算法后，可以移除这两项参数，或者可以选择更小的L2正则约束参数率，因为BN具有提高网络泛化能力的特性。\n",
    "-  再也不需要使用局部响应归一化层。\n",
    "-  可以把训练数据彻底打乱。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 批量正则化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 权重初始化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 选择合适的激活函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 选择合适激活函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 选择合适优化器"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 传统梯度优化的不足"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2 动量算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.3 AdaGrad 算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.4 RMSProp 算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.5 Adam 算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 GPU加速"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1 单GPU加速"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.2 多GPU加速"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.3 使用GPU注意事项"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 视觉处理基础"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 自然语言处理基础\n",
    "\n",
    "## 4. 生成式深度学习\n",
    "\n",
    "# 二、 深度学习实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eab82ac3e8dace506f238f2c78517d0344f5c2d331c76485024c915e2de45b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
