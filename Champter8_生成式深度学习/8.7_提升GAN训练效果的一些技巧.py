# -*- encoding: utf-8 -*-
"""
@File       : 8.7_提升GAN训练效果的一些技巧及小结.py
@Time       : 2023/8/10 13:15
@Author     : yanpenggong
@Email      : yanpenggong@163.com
@Version    : 1.0
@Copyright  : 侵权必究
"""

# import some packages
# --------------------

一、提升GAN训练效果的一些技巧：
    训练GAN是生成器和判别器互相竞争的动态过程，比一般的神经网络挑战更大。
    为了克服训练GAN模型的一些的问题，人们从实践中总结一些常用方法，这些方法在一些情况下，效果不错。
    这些方法不一定适合所有情况，方法如下：
        1. 批量加载和批规范化，有利于提升训练过程中博弈的稳定性。
        2. 使用 tanh 激活函数作为生成器最后一层，将图像数据规范在 [-1, 1]， 一般不用 sigmoid。
        3. 选用 Leaky ReLU 作为生成器和判别器的激活函数，有利于改善梯度的稀疏性，稀疏的梯度会妨碍GAN的训练。
        4. 使用卷积层时，考虑卷积核的大小能被步幅整除，否则，可能导致生成的图像中存在棋盘状伪影。