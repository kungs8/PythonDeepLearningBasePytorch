# -*- encoding: utf-8 -*-
'''
@File       : 8.4_VAE与GAN的优缺点.py
@Time       : 2023/07/03 14:32:44
@Version    : 1.0
@Author     : yanpenggong
@Email      : yanpenggong@163.com
@Copyright  : 侵权必究
'''

# import some packages
# --------------------
VAE和GAN都是生成模型(Generative MOdel)。即能生成样本的模型，利用这类模型，可以完成图像自动生成(采样)、图像信息补全等工作。
VAE是利用自己已有图像再编码器生成潜在向量，这个向量在服从搞死分布的情况下很好地保留了原图像的特征，在解码器得到的图片会更加的合理与准确。
VAE适合学习具有良好结构的潜在空间，潜在空间有比较好的连续性，其中存在一些有特定意义的方向。VAE能够捕捉到图像的结构变化(倾斜角度、圈的位置、形状变化、表情变化等)。这也是VAE的一大优点，他有显式的分布，能够容易地可视化图像的分布。
但是图像在训练的时候损失函数只能用均方误差(MSE)之类的粗略误差衡量，这就导致生成的图像不能很好地保留原图像的清晰度，就会使得图像看上去有点模糊。
GAN生成的潜在空间可能没有良好结构，但生成的图像一般比VAE的更清晰。
在GAN的训练过程中容易发生崩溃，以及训练时梯度消失情况的发生。生成对抗网络的博弈理论只是单纯的让G生成的图像骗过D，这个会让G钻空子一旦骗过D，
不论图像的合不合理就作为输出，于是模型坍塌(Generative Model)就发生了。

GAN生成器的损失函数(Loss)依赖于判别器Loss后向传递，而不是直接来自距离，因而若判别器总是能准确地判别出真假，则向后传递的信息就非常少，导致生成器无法形成自己的Loss，这就是GAN比较难训练的原因。
当然针对这一不足，近些年采用的一个新的距离定义(Wasserstein Distance)应用于判别器，而不是原型中简单粗暴的对真伪样本的分辨正确的概率。

优缺点汇总：
    - GAN 生成的效果优于VAE
    - GAN 比VAE更难训练