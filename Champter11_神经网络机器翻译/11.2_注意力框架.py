# -*- encoding: utf-8 -*-
"""
@File       : 11.2_注意力框架.py
@Time       : 2023/8/28 16:03
@Author     : yanpenggong
@Email      : yanpenggong@163.com
@Version    : 1.0
@Copyright  : 侵权必究
"""
在生成目标句子的单词时，不论生成哪个单词，是y1、y2也好，还是y3也好，使用的句子X的语义编码C都是一样的，没有任何区别。
而语义编码C是由句子X的每个单词经过Encoder编码产生的，这意味着不论是生成哪个单词，y1、y2、y3，其实句子X中任意单词对生成某个目标单词yi来说影响力都是相同的，没有任何区别。
eg(输入英文输出中文)：
    输入：Tom chase Jerry，Encoder-Decoder框架逐步生成中文单词："汤姆", "追逐", "杰瑞"
    1. 在翻译"杰瑞"这个中文单词的时候，分心模型里面的每个英文单词对于翻译目标单词"杰瑞"贡献是相同的，很明显这里不太合理，显然"Jerry"对于翻译成"杰瑞"更重要，
        但是分心模型是无法体现这一点的，这就是为何说它没有引入注意力的原因。
    2. 没有引入注意力的模型，在输入句子比较短的时候估计问题不大，但是如果输入句子比较长，此时所有语义完全通过一个中间语义向量来表示，
        单词自身的信息已经消失，这会丢失很多细节信息，这也是为何要引入注意力模型的重要原因。
    3. 如果引入AM(Attention Model)模型的话，应该在翻译"杰瑞"的时候，体现出英文单词对于翻译当前中文单词不同的影响程度，比如给出类似这样的一个概率分布：
        (Tom, 0.3)、(Chase, 0.2)、(Jerry, 0.5)
    每个英文单词的概率代表了翻译当前单词"杰瑞"时，注意力分配模型分配给不同英文单词的注意力大小。
    这对于正确翻译目标语单词肯定是有帮助的，因为引入了新的信息。
    同理，目标句子中的每个单词都应该学会其对应的原语句中单词的注意力分配概率信息。这意味着在生成每个单词yi的时候，原先都是相同的中间语义C会替换成根据当前生成单词而不断变换的Ci。
    AM(Attendtion Model)关键点：
        由固定的中间语义表示C换成了根据当前输出单词来调整加入注意力模型的变化的Ci。
    y1 = g(C1)
    y2 = g(C2,y1)
    y3 = g(C3,y1,y2)
    而每个Ci可能对应着不同的原语句子单词的注意力分配概率分布，比如注意力分布矩阵：
        A = [a_{ij}] = [
            [0.6 0.2 0.2]
            [0.2 0.7 0.1]
            [0.3 0.1 0.5]]
    第i行表示yi收到的所有来自输入单词的注意力分配概率。yi的语义向量Ci由这些注意力分配概率和Encoder对单词xj的转换函数f2相乘，计算而得：
        C1 = C汤姆 = g(0.6*f2("Tom"), 0.2*f2("Chase"), 0.2*f2("Jerry"))
        C2 = C追逐 = g(0.2*f2("Tom"), 0.7*f2("Chase"), 0.1*f2("Jerry"))
        C3 = C杰瑞 = g(0.3*f2("Tom"), 0.1*f2("Chase"), 0.5*f2("Jerry"))
    其中，f2函数代表Encoder对输入英文单词的某种变换函数，比如如果Encoder用的是RNN模型的话，这个f2函数的结果往往是某个时刻输入xi后隐层节点的状态值；
    g代表Encoder根据单词的中间表示合成整个句子的中间语义表示的变换函数，一般来说，g函数是对构成元素加权求和，即：
        $C_{i} = \Sigma_{j=1}^{T_{x}}\alpha_{ij}h_{j}$
    假设Ci中 那个i是"汤姆",那么T_{x}就是3，代表输入句子的长度
    h1=f2("Tom")、h2=f2("Chase")、h3=f2("Jerry")对应的注意力模型权重分别是0.6，0.2，0.2,所以g函数就是个加权求和函数。

    目的是要计算生成yi时，对输入句子中的单词"Tom"、"Chase"、"Jerry"，其对yi的注意力分配概率分布。
    这些概率可以用目标输出句子i-1时刻的隐层节点状态H_{i-1}去一一和输入句子中每个单词对应的RNN隐层节点状态hj进行对比，即通过对齐函数F(hj,H_{i-1})来获得目标单词和每个输入单词对应的对齐可能性。
    函数F(hj, H_{i-1})在不同论文可能会采取不同的方法，然后函数F的输出经过softmax进行归一化得到[0, 1]的注意力分配概率分布数值。

上述是Soft Attention Model 的基本思想。
AM(Attention Model)模型的物理意义：
    一般文献会把AM模型看作是单词对齐模型，这是非常有道题的。目标句子生成的每个蚕子对应到输入句子单词的概率分布可以理解为输入句子单词和这个目标生成单词的对齐概率，这在机器翻译语境下是非常直观的。
AM概念：把AM模型理解成影响力模型也是合理的。就是说生成目标单词的时候，输入句子每个单词对于生成这个单词有多大的影响程度。这种想法也是理解AM模型物理意义的一种方式。
注意力机制除Soft Attention还有：
    - Hard Attention
    - Global Attention
    - Local Attention
    - Self Attention
    - 等