# PythonDeepLearningBasePytorch

# 一、 深度学习基础

>**`*.ipynb`转为需要的文档格式**
>```bash
># 进入到指定路径下
>cd ./GGG/PytorchLearning/PythonDeepLearningBasePytorch/
>```
>- **转换为 markdown 文件**
> 	 ```bash
> 	 jupyter nbconvert --to markdown notebook.ipynb
> 	 ```
>- **转换为 html 文件**
> 	 ```bash
> 	 jupyter nbconvert --to html notebook.ipynb
> 	 ```
>- **转换为 pdf 文件**
> 	 ```bash
> 	 jupyter nbconvert --to pdf notebook.ipynb
> 	 ```

## 1. 机器学习基础

### 1.1 机器学习的基本任务

机器学习的基本任务一般分为4大类：
- 监督学习
    - 定义: 使用已知正确答案的示例来训练模型
    - 任务: 分类、回归、目标检测、识别 等
    - 场景: 根据已有数据，分类或预测新数据
- 无监督学习
    - 定义: 在无标签的数据集中插值规则的模型
    - 任务: 聚类、降维 等
    - 场景: 从一堆人的身体测量值中算出XS、S、M、L 和 XL 号衬衫尺码
- 半监督学习
    - 定义: 结合分类与聚类的思想生成新模型
    - 任务: 自编码、推荐、生成式对抗 等
    - 场景: 根据已有数据，分类 或 预测 新数据
- 强化学习
    - 定义: 对没有标注数据集，但知是否更近目标来构建模型
    - 任务: 分类、 回归 等
    - 场景: 类似经典的儿童游戏 -- "hotter or colder"

#### 1.1.1 监督学习
监督学习是最常见的一种机器学习类型，其任务的特点是给定学习目标，这个学习目标又称标签、标注 或 实际值 等，
整个学习过程就是围绕如何使预测与目标更接近而来的。
近些年，随着深度学习的发展，分类除传统的二分类、多分类、多标签分类之外，也出现了一些新的内容: 
eg: 目标检测、目标识别、图像分割 等 监督学习的重要内容。 
监督学习过程:

    +-----------------------|    预处理    |    学习    |    验证    ｜      预测      ｜-------+
    |                               +<-----------+         |标签|-->+                        |
    |                               | 调整模型参数 |           |      |                       |
    | |原始数据|标签|->Shuffle-->|训练数据|----->|计算损失|-->|最终模型|--+->|不带标签的新数据|      |
    |                                                        |      |         |             |
    |                          |测试数据|------------------>--+      |          +>|标签|      |
    |                          |       |---------<------------------+                       |
    +-----------------------|    预处理    |    学习    |    验证    ｜      预测      ｜-------+

#### 1.1.2 无监督学习
监督学习的输入数据中有标签或目标值，但在实际生活中，有很多数据没有标签 或者 标签代价很高。
这些没有标签的数据也可能包含很重要的规则或信息，从这类数据中学习到一个规则或规律的过程被称为无监督学习。
在无监督学习中，我们通过推断输入数据的结构来建模，模型包括关联学习、降维、聚类 等。

#### 1.1.3 半监督学习
- 半监督学习是监督学习 与 无监督学习相结合的一种学习方法。 x
- 半监督学习使用大量的未标记数据，同时由部分使用标记数据进行模式识别。 
- 自编码器是一种半监督学习，其生成的目标就是未经修改的输入。 
- 语言处理中根据给定文本中的词预测下一个词，也是半监督学习的例子。 
- 对抗生成式网络也是一种半监督学习，给定一些真图片或语言，然后通过对抗生成网络生成一些与真图片或语言逼真的图形或语言。

#### 1.1.4 强化学习
强化学习是机器学习的一个重要分支没事多学科领域交叉的一个产物。
强化学习主要包含 4 个元素:
- 智能体(Agent)
- 环境状态
- 行动
- 奖励

强化学习的目标就是获得最多的累计奖励。
强化学习把学习看作一个试探评价的过程，Agent 选择一个动作用于环境，
环境接受该动作后状态发生变化，同时产生一个强化信号(奖或惩)反馈给 Agent，
Agent 根据强化信号和环境当前状态再选择下一个动作，选择的原则是使受到正强化(奖)的概率增大。
选择的动作不仅影响立即强化值，也影响下一时刻的状态和最终的强化值。

强化学习不同于监督学习，主要表现在教师信号上。
强化学习中由环境提供的强化信号是 Agent 对所产生动作的好坏做的一种评价，而不是告诉 Agent 如何去产生正确的动作。
由于外部环境只提供了很少的信息，所以 Agent 必须靠自身的经历进行学习。
通过这种方式，Agent 在行动一一被评价的环境中获得知识，改进行动方案以适应环境。

AlphaGo Zero 带有强化学习内容，它完全摒弃了人类知识，碾压了早期版本的 AlphaGo，更显现了强化学习和深度学习结合的强大威力。

### 1.2 机器学习一般流程
机器学习一般需要先定义问题、收集数据、探索数据、预处理数据，对数据处理后，接下来开始训练模型、评估模型，然后优化模型等步骤。

```bash
+----------------+---------+---------------------------------+-----------------------+-----------|
| 明确目标(收集数据)| 输入数据 |          数据探索与预处理          |   训练及测试算法或建模   |    评估    |
|----------------+---------+---------------------------------+-----------------------+-----------|
|                |         |                      数据清洗   -|->  训练数据 -> 模型训练<-+-<---+     |
|                | 数据集合-|-> 数据探索与预处理 -->  数据转换    |               模型     |     |     |
|                |         |                      补充规范数据-|->  测试数据 -> 测试模型--+->评估及优化 |
|                |         |                                 |                       |   +-> 部署 |
+----------------+---------+---------------------------------+-----------------------+-----------|
```

#### 1.2.1 明确目标
在实施一个机器学习项目之初，定义需求、明确目标、了解要解决的问题以及目标设计的范围等都非常重要，它们之间影响后续工作的质量甚至成败。
1) 明确目标
    首先需要明确大方向，比如当前的需求是分类问题还是预测问题或聚类问题等。
2) 明确目标具体含义 \
清除大方向后，需要进一步明确目标的具体含义。
    - 如果是分类问题，还需要区分是二分类、多分类还是多标签分类。
    - 如果是预测问题，要去吧是标量预测还是向量预测。
    - ...
3) 确定问题
    明确目标有助于选择模型架构、损失函数及评估方法等。
当然，明确目标还包含需要了解目标的可行性，因为并不是所有问题都可以通过机器学习来解决。

#### 1.2.2 收集数据
为解决上述的问题，需要哪些数据？数据是否充分？哪些数据能获取，哪些数据无法获取？这些数据是否包含我们学习的一些规则等。
接下来是收集数据，数据可能涉及不同平台、不同系统、不同部分、不同形式等，对这些问题的了解有助于确定具体数据收集方案、实施步骤等。
能收集的数据尽量实现自动化、程序化。

#### 1.2.3 数据探索与预处理
收集到的数据，不一定规范和完整，这就需要对数据进行初步分析或探索，然后根据探索结果与问题目标，确定数据预处理方案。
对数据探索包括 了解数据的大致结构、数据量、各特征的统计信息、整个数据质量情况、数据的分布情况等。
为了更好的体现数据分布情况，数据可视化是一个不错的方法。

通过对数据探索后，可能会发现不少问题：如存在缺失数据、数据不规范、数据分布不均衡、存在奇异数据、有很多非数值数据、存在很多无关或不重要的数据等。
这些问题的存在直接影响数据质量，为此，数据预处理工作就应该是接下来的重点工作。
数据预处理是机器学习过程中必不可少的重要步骤，特别是在生产环境中的机器学习，数据往往是原始、未加工和未处理过的，数据预处理常常占据整个机器学习过程的大部分时间。

数据预处理过程，一般包括数据清理、数据转换、规范数据、特征选择等工作。

#### 1.2.4 选择模型及损失函数
数据准备好后，接下来就是根据目标选择模型。
模型选择可以先用一个简单、自身比较熟悉的方法来实现，用这个方法开发一个原型或比基准更好一点的模型。通过这个简单模型有助于快速了解整个项目的主要内容。
- 了解整个项目的可行性、关键点。
- 了解数据质量、数据是否充分等。
- 为开发一个更好的模型奠定基础。

在模型选择时，一般不存在某种对任何情况都表现很好的算法(这种现象又称为"没有免费的午餐")。
因此在实际选择时，一般会选用几种不同的方法来训练模型，然后比较它们的性能，从中选择最优的那个。

模型选择后，还需要考虑以下几个关键点：
- 最后一层是否需要添加 softmax 或 sigmoid 激活层。
- 选择合适损失函数。
- 选择合适的优化器。

下面提供了常见问题类型 最后一层激活函数 和 损失函数 的对应关系：

```bash
+--------------+----------------+--------------------------------------------------------------------------+
| 问题类型      |  最后一层激活函数 |    损失函数                                                               |
+--------------+----------------+--------------------------------------------------------------------------+
| 二分类，单标签 ｜      添加      | sigmoid 层 nn.BCELoss                                                     |
|              |      不添加     | sigmoid 层 nn.BCEWithLogitsLoss                                          |
| 二分类，多标签  |      无        | nn.SoftMarginLoss(target 为 1 或 -1)                                     |
| 多分类，单标签  |      不添加    | softmax 层 nn.CrossEntroyLoss(target 的类型为 torch.LongTensor 的 one-hot) |
|              |      添加      | softmax 层 nn.NLLLoss                                                     |
| 多分类，多标签  |      无       | nn.MultiLabelsoftMarginLoss(target 为 0 或 1)                             |
| 回归          |      无        | nn.MSELoss                                                               |
| 识别          |      无        | nn.TripleMarginLoss                                                      |
|              |                | nn.CosineEmbeddingLoss(margin 在 [-1, 1] 之间)                            |
+--------------+----------------+--------------------------------------------------------------------------+
```

#### 1.2.5 评估及优化模型
模型确定后，还需要确定一种评估模型性能的方法，即评估方法。评估方法大致有 3 种：
- 留出法
    留出法的步骤相对简单，直接将数据集划分为两个互斥的集合，其中一个集合作为训练集，另一个作为测试集。 \
    在训练集上训练出模型后，用测试集来评估测试误差，作为泛化误差的估计。 \
    使用留出法，数据量较大时还可以优化出一种更好的方法，就是把数据分成 3 部分： \
    - 训练数据集: 用来训练模型。 \
    - 验证数据集: 用来调优超参数。 \
    - 测试数据集: 用来测试模型的泛化能力。 \
- K折交叉验证 \
    不重复地随机将训练数据集划分为 k 个，其中 k-1 个用于模型训练，剩余的一个用于测试。
- 重复的K折交叉验证 \
    当数据量比较小，数据分布不很均匀时，可以采用这种方法。

使用训练数据构建模型后，通常使用测试数据对模型进行测试，测试模型对新数据的适应情况。
- 如果对模型的测试结果满意，就可以用此模型对以后的数据进行预测；
- 如果对模型的测试结果不满意，可以优化模型。

模型优化的方法很多，其中网格搜索参数是一种有效方法，当然也可以采用手工调节参数等方法。
如果出现过拟合，尤其是回归类的问题，可以考虑正则化的方法来降低模型的泛化误差。

### 1.3 过拟合与欠拟合

#### 1.3.1 权重正则化

#### 1.3.2 Dropout 正则化

#### 1.3.3 批量正则化

#### 1.3.4 权重初始化

### 1.4 选择合适的激活函数

### 1.5 选择合适激活函数

### 1.6 选择合适优化器

#### 1.6.1 传统梯度优化的不足

#### 1.6.2 动量算法

#### 1.6.3 AdaGrad 算法

#### 1.6.4 RMSProp 算法

#### 1.6.5 Adam 算法

### 1.7 GPU加速

#### 1.7.1 单GPU加速

#### 1.7.2 多GPU加速

#### 1.7.3 使用GPU注意事项

## 2. 视觉处理基础

## 3. 自然语言处理基础

## 4. 生成式深度学习

# 二、 深度学习实践


```python

```
