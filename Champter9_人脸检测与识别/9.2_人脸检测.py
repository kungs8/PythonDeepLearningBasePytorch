# -*- encoding: utf-8 -*-
"""
@File       : 9.2_人脸检测.py
@Time       : 2023/8/10 14:44
@Author     : yanpenggong
@Email      : yanpenggong@163.com
@Version    : 1.0
@Copyright  : 侵权必究
"""

# import some packages
# --------------------
人脸检测是目标检测的一种。在介绍人脸检测之前，先简单介绍下目标检测，再详细介绍人脸检测中的人脸定位、对齐及主要算法等。

1. 目标检测
    目标检测早期框架：Viola Jones框架、HOG(Histogram of Oriented Gradients)架构。
    加入深度学习后的框架，包括：OverFeat、R-CNN、Fast R-CNN、Faster R-CNN等。
    深度学习的方法是计算机视觉中真正的"变革者"，在图像分类任务上已全面超越其他经典模型，深度学习模型在目标检测领域也是最好的方法。

    目标检测(Object Detection) 是找出图像中所有感兴趣的目标(物体)，确定它们的类别和位置，是计算机视觉领域的核心问题之一。
    由于各类物体有不同的外观、形状、姿态，加上成像时光照，遮挡等因素的干扰，使目标检测是计算机视觉领域最具有挑战性的问题之一。
    目标检测要解决的主要问题：
        - 确定目标的位置、形状和范围
        - 区分各种目标

    深度学习的一些目标检测算法：
        1) OverFeat
            OverFeat 是第一个使用深度学习进行目标检测并取得很大进展的方法，是纽约大学在2013年提出的。提出了一个使用卷积神经网络(CNN)的多尺度滑动窗口算法。
        2) R-CNN
            R-CNN(Regions with CNN Features)是在OverFeat 提出不久，由加州大学伯克利分校的Ross Girshick等人发表了基于卷积神经网络特征的区域方法，
            它在目标检测比赛上相比以往方法取得了50%的性能提升。
            R-CNN使用CNN(ConvNet) 对区域抽取特征向量，实现了从经验驱动特征(SIFT、HOG)到数据驱动特征(CNN Feature Map)的转换，从而极大地提高了特征对样本的处理和表达能力。
        3) Fast R-CNN
            R-CNN提出一年后，微软亚洲研究院提出了Fast R-CNN，这个方法迅速地演化成了一个纯深度学习的方法。
            与R-CNN相似，它也使用选择性搜索来生成候选区域，但与R-CNN不同的是，Fast R-CNN在整张图上使用CNN来提取特征，
            然后在特征图上使用区域兴趣池化(Region of Interest， ROI)，最后用前馈神经网络来进行分类和回归。
            这个方法不仅快，而且由于ROI池化层和全连接层的存在，该模型可以进行端对端的求导，并且训练也更容易。
            缺陷：该模型仍旧依赖选择性搜索。
        4) Faster R-CNN
            Faster R-CNN 依然采用选择性搜索方法，这些算法在CPU上运行且速度很慢。为解决这个问题，任少卿团队提出了Faster R-CNN，这是R-CNN的第3代。
            此模型增加了一个所谓的"区域候选网络(Region Proosal Network, RPN)"，RPN在生成ROI时效率更高，将摆脱搜索选择算法，从而让模型实现完全端到端的训练。

2. 人脸定位
    人脸检测需要解决的问题就是给定任意图像，找到其中是否存在一个或多个人脸，并返回图像中每个人的位置、范围及特征等。
    人脸检测包括定位、对齐、确定关键点等过程。

    定位就是在图像中找到人脸的位置。在这个过程中输入的是一张含有人脸的图像，输出的是所有人脸的矩形框。
    一般来说，人脸检测应该能够检测出图像中所有人脸，不能有漏检，更不能有错检。

3. 人脸对齐(Face Alognment)
    同一个人在不同的图像序列中可能呈现出不同的姿态和表情，这种情况是不利于人脸识别的。
    有必要将人脸图像都变换到一个统一的角度和姿态，这就是人脸对齐。它的原理是找到人脸的若干个关键点(基准点，eg: 眼角、鼻尖、嘴角等)，
    然后利用这些对应的关键点通过相似变换(Similarity Transform，旋转、缩放和平移)将人脸尽可能变换到标准人脸。

    人脸定位和人脸对齐等任务，可以使用 MTCCN算法 完成。
    MTCNN(Multi-task Cascaded Convolutional Networks)算法是用来同时实现Face Detection 和 Alognment，也就是人脸检测和对齐。
    MTCNN 基于深度学习(CNN)的人脸检测和人脸对齐方法，相比于传统的算法，它的性能更好，检测速度更快。

4. MTCNN 算法
    MTCNN算法是深圳先进技术研究院乔宇团队提出的，MTCNN 由3个神经网络组成，分别是PNet、RNet和ONet。
    MTCNN 算法流程：
        1) 对给定的一张图像，进行缩放生成不同大学的图像，构建图像金字塔，以便适应不同尺寸的头像。
        2) 利用 P-Net 网络生成候选窗口和边框回归向量，通过利用边框回归(Bounding Box Regression)的方法来校正这些候选窗口，
            同时使用非极大值抑制(NMS，主要功能就是抑制这些分类概率不是局部极大的候选窗口)合并重叠的窗口。
        3) 使用R-Net网络改善候选窗口。将通过P-Net的候选窗口输入到R-Net中，拒绝掉大部分假窗口，继续使用边框回归校正窗口和非极大值抑制合并窗口。
        4) 使用O-Net 网络输出最终的人脸框和5个特征点的位置。
    从P-Net到R-Net，再到最后的O-Net，网络输入的图像越来越大，卷积层的通道数也越来越多，网络的深度也越来越深，因此识别人脸的准确率也越来越高。
    同时P-Net网络的运行速度较快，R-Net次之O-Net运行速度最慢。之所以使用这3个网络，是因为一开始如果直接对图像使用O-Net网络，速度非常慢。
    实际上P-Net先做了一层过滤，将过滤后的结果再交给R-Net进行过滤，最后将过滤后的结果交给效果最好但是速度最慢的O-Net进行识别。
    这样在每一步都提前减少了需要判别的数量，有效地降低了计算时间，从而大大提高运行效率。