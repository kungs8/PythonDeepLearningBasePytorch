# -*- encoding: utf-8 -*-
"""
@File       : 9.4_人脸识别.py
@Time       : 2023/8/10 18:10
@Author     : yanpenggong
@Email      : yanpenggong@163.com
@Version    : 1.0
@Copyright  : 侵权必究
"""

# import some packages
# --------------------
1. 人脸识别主要原理
    输入是标准化的人脸图像，通过对特征建模得到向量化的人脸特征，最后通过分类器判别得到识别的结果。
    这里的关键是怎样得到对不同人脸有区分度的特征，通常我们在识别一个人时会看它的眉形、脸轮廓、鼻子形状、眼睛的类型等，人脸识别算法引擎要通过训练得到类似这样的有区分度的特征。

2. 人脸识别发展
    1) 特征提取改进
        一开始是人工提取，然后发展成通过神经网络、卷积神经网络 采用自提取，代表网络是Facenet
    2) 损失函数的改进
        使用的是经典的交叉熵损失函数(Softmax) 进行问题优化，最后通过特征嵌入(Feature Embedding)得到固定长度的人脸特征向量。
        信息熵主要用于类别分类，但要同类之间向量之间尽可能接近，不同类别之间向量尽可能远等方面的要求却不够理想。为此想到很多改进方法：
            - Google提出FaceNet，使用三元组损失函数(Triplet Loss)代替常用的Softmax交叉熵损失函数，在一个超球空间上进行优化使类内距离更紧凑，类间距离更远。
            - Triplet Loss 虽然优化目标很明确很合理，但是需要研发人员具有丰富的数据工程经验。
        为了解决这个问题，ECCV2016一篇文章提出了权衡的解决方案。通过添加Center Loss 对特征层进行优化并结合Softmax就能够训练出拥有内聚性良好的特征。
        该特点在人脸识别上尤为重要，从而使得在很少的数据情况下训练出来的模型也能够有不俗的性能。
        Center Loss 在Softmax 的基础上加入了一个维持类别中心的损失函数，并能使特征向量所属类别中心聚拢，从而使达到了和Triple Loss类似的效果。

        后续对网络层进行优化，如L-Softmax 把最后一层的偏移量取消。
        SphereFace提出了A-Softmax，针对L-Softmax做出了微小的改进，归一化了权重，可以看成在一个超球面的流形上对样本进行分类判别。
        后来AM-Softmax的改进版本，直接针对角度去加Margin，这样做的好处是角度距离比余弦距离在对角度的影响更加直接。ArcFace同时对特征和权重归一化等优化。